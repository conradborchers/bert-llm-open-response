{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6546,"status":"ok","timestamp":1723578826196,"user":{"displayName":"Danielle Thomas","userId":"12678519897137807718"},"user_tz":240},"id":"U3y0JUEVu_Zu","outputId":"2c5e3d82-4a3d-478e-d0ec-4e49ba2a5cf9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting openai\n","  Downloading openai-1.40.6-py3-none-any.whl.metadata (22 kB)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n","Collecting httpx<1,>=0.23.0 (from openai)\n","  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n","Collecting jiter<1,>=0.4.0 (from openai)\n","  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n","Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n","Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n","  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n","Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n","  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n","Downloading openai-1.40.6-py3-none-any.whl (361 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m361.3/361.3 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: jiter, h11, httpcore, httpx, openai\n","Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 jiter-0.5.0 openai-1.40.6\n"]}],"source":["!pip install openai  # OpenAI API for prompting GPT-4o"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8IkheaXGsir1"},"outputs":[],"source":["import openpyxl\n","from openai import OpenAI\n","import os\n","import json\n","from tqdm import tqdm"]},{"cell_type":"markdown","metadata":{"id":"qmGkH0WztTIc"},"source":["# Reading Excel Sheet"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vy8VfjjdtJsh"},"outputs":[],"source":["path = \"Rerun_input.xlsx\"\n","workbook = openpyxl.load_workbook(path)\n","sheet = workbook.active  # There is only one sheet, so no ambiguity here."]},{"cell_type":"markdown","metadata":{"id":"5uKQIYXct0_j"},"source":["Get all the responses and scores"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SaaEXbQ_tjSs"},"outputs":[],"source":["INPUT_COLUMN = 31 # Specify the column from which input is read (A->1, B->2, etc.)\n","row_count = 215 # sheet.max_row  # Get number of rows. If number of rows to read is already known (or sheet does not terminate where data terminates), place number here (+1) instead.\n","inputs = [sheet.cell(row=i, column=INPUT_COLUMN).value  for i in range(2, row_count + 1)]  # Column number is set here. YOUR INPUT COLUMN NUMBER GOES HERE.\n","inputs = [x for x in inputs if x is not None]"]},{"cell_type":"markdown","metadata":{"id":"qASEYdU1vH08"},"source":["# OpenAI and Prompt Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AGO9f6uLvKiB"},"outputs":[],"source":["# Insert your API Key for OpenAI here."]},{"cell_type":"markdown","metadata":{"id":"HhcWKgsOP_gx"},"source":[]},{"cell_type":"markdown","metadata":{"id":"cKg2bQ7qvi_i"},"source":["Scoring Prompt Input"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wfyoLemuvkrN"},"outputs":[],"source":["SCORING_PROMPT_START = \"\"\"\n","Please score the following tutor response to a tutor training scenario involving a middle school student facing a microaggression as follows:\n","-if the tutor’s response acknowledges a student facing a microaggression and provides support to the student, by giving the student space to talk, or facilitating an apology, score with a 1. Sample responses scoring a 1 are \"Nori, I heard what your teacher said about the exit ticket. It's okay to find problems challenging. Let's work on it together during our session. Your efforts are important, and I'm here to support you.\" and \"Nori, I noticed what your teacher said to you could have been upsetting and I am here if you would like to talk about it.\" Sample response scoring a 1 include: \"Nori, I noticed what your teacher said to you could have been upsetting and I am here if you would like to talk about it.\" and \"Nori, I heard what your teacher said about the exit ticket. It's okay to find problems challenging. Let's work on it together during our session. Your efforts are important, and I'm here to support you.\"\n","-if the tutor’s response does not acknowledge the microaggression or does not provide any support to the student, score with a 0. Sample responses scoring a 0 are \"Nothing is too difficult if you decide you want to do it Nori. You are capable.\" and \"Do want to talk about what the teacher said to you?\"\n","\n","\n","Response Start ---\n","\"\"\"\n","\n","\n","SCORING_FORMAT_PROMPT = \"\"\"\n","--- Response End. Given the earlier response, please return a JSON string following the format, {\\\"Rationale\\\": \\\"your reasoning here\\\", \\\"Score\\\":0/1}.\n","\"\"\"\n"]},{"cell_type":"markdown","metadata":{"id":"HH0uEw5_ythd"},"source":["Feedback Elaboration Prompt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jJcXaVTByysS"},"outputs":[],"source":["# Second prompt: Pass feedback and the original input to the rewriter. Can omit the original input later to save on token cost.\n","\n","FEEDBACK_PROMPT_START = \"\"\"\n","Please write the following third-person feedback about a tutor into the second person. In doing so, please address the tutor directly and do not exceed 100 words.\n","Please start with positive feedback, if any. Subsequently, please provide any critiques, if applicable, in a constructive tone.\n","\n","Third-person Feedback Start ---\n","\"\"\"\n","\n","# Design choice: Passing original input to potentially provide more concrete second-person feedback (original feedback could be high-level). Can omit to reduce cost\n","ORIGINAL_RESPONSE_PROMPT = \"\"\"\n","--- Third-person Feedback End. For further context, the original feedback was provided for the following response:\n","\n","Response Start ---\n","\"\"\"\n","\n","FEEDBACK_FORMAT_PROMPT_WITH_RESPONSE = \"\"\"\n","--- Response End. Please return your refined feedback, based on the original response and the third-person feedback, in a JSON string following the format, {\\\"Feedback\\\": \\\"your response here\\\"}.\n","\"\"\"\n","\n","FEEDBACK_FORMAT_PROMPT_WITHOUT_RESPONSE = \"\"\"\n","--- Third-person Feedback End. Please return your refined feedback, based on the third-person feedback, in a JSON string following the format, {\\\"Feedback\\\": \\\"your response here\\\"}.\n","\"\"\""]},{"cell_type":"markdown","metadata":{"id":"VuVI8e8kxT87"},"source":["Helper function for response parsing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uIlxCT-ixV5J"},"outputs":[],"source":["def extract_response(response_obj, json=False):\n","  role = response_obj.choices[0].message.role\n","  content = response_obj.choices[0].message.content\n","  if json:\n","    return {\"role\": role, \"content\": content}\n","  else:\n","    return (role, content)"]},{"cell_type":"markdown","metadata":{"id":"jIHBTOqTwW1T"},"source":["## OpenAI API Call"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":296900,"status":"ok","timestamp":1723579149185,"user":{"displayName":"Danielle Thomas","userId":"12678519897137807718"},"user_tz":240},"id":"Ms4Iojj3wWGw","outputId":"1211a9bb-f073-4dd6-e779-32ccd2dd3aab"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 212/212 [04:56<00:00,  1.40s/it]\n"]}],"source":["# Iterate over all responses\n","MAX_TOKENS = 300\n","TEMPERATURE = 0\n","RUN_UP_TO = -1  # Sets a maximum index for responses to run. Useful to specify how many responses we want to run on (partial execution). Set to -1 to run them all.\n","TWO_STAGE = False  # Specifies whether to refine the feedback provided by the scoring prompt\n","TWO_STAGE_INCLUDE_RESPONSE = False # Specifies whether the second-stage prompt uses the original response.\n","SCORE_COLUMN = 32  # Change column numbers here to  modify where output is written\n","RATIONALE_COLUMN= 33\n","REFINED_RATIONALE_COLUMN= 34\n","\n","\n","MODEL = \"gpt-4o\"\n","\n","# Add titling to the new columns\n","output_score_title = sheet.cell(row=1, column=SCORE_COLUMN)  # Output Score Column goes here. CHANGE COLUMN NUMBER to set score output location\n","output_score_title.value = \"OpenAI Score\"  # OPTIONAL: Sets title cell in row 1. Comment out to disable this\n","\n","rationale_title = sheet.cell(row=1, column=RATIONALE_COLUMN)\n","rationale_title.value = \"OpenAI Rationale\"\n","\n","if TWO_STAGE:  # Creates a new column for the refined rationale\n","  refined_rationale_title = sheet.cell(row=1, column=REFINED_RATIONALE_COLUMN)\n","  if TWO_STAGE_INCLUDE_RESPONSE:  # If the second-stage prompt also uses the original response, use a different column title\n","    refined_rationale_title.value = \"Refined Feedback (w/ Response in prompt)\"\n","  else:\n","    refined_rationale_title.value = \"Refined Feedback (w/o response in prompt)\"\n","\n","\n","if RUN_UP_TO >=  0:  # If an upper bound is set\n","  inputs_upto = inputs[:RUN_UP_TO]\n","else:\n","  inputs_upto = inputs  # Take the whole set of responses\n","\n","for index, inpt in tqdm(enumerate(inputs_upto), total=len(inputs_upto)):\n","  overall_history = [{\"role\": \"system\", \"content\": SCORING_PROMPT_START}, {\"role\": \"user\", \"content\": inpt}, {\"role\": \"system\", \"content\": SCORING_FORMAT_PROMPT}]\n","  openai_out = client.chat.completions.create(model=MODEL, messages=overall_history, max_tokens=MAX_TOKENS, temperature = TEMPERATURE)\n","  role, content = extract_response(openai_out)\n","  # We now need to parse the JSON into rational and score\n","  score_cell = sheet.cell(row=index+2, column=SCORE_COLUMN) # Score cell\n","  rationale_cell = sheet.cell(row=index+2, column=RATIONALE_COLUMN)  # Rationale cell\n","  refined_feedback_cell = sheet.cell(row=index+2, column=REFINED_RATIONALE_COLUMN)  # Refined feedback cell\n","  try:\n","    content_json = json.loads(content)  # Run response through JSON\n","    score = str(content_json[\"Score\"])  # Cast to string to avoid type inequality\n","    rationale = str(content_json[\"Rationale\"])  # Fetch the rationale\n","\n","    score_cell.value = score  # Now write both into the Excel sheet\n","    rationale_cell.value = rationale\n","\n","    if TWO_STAGE:  # If we are to refine the feedback\n","      if TWO_STAGE_INCLUDE_RESPONSE: # If we also want to pass the response, then we need to use a longer prompt, specified next:\n","        refinement_history = [{\"role\": \"system\", \"content\": FEEDBACK_PROMPT_START}, {\"role\": \"user\", \"content\": rationale}, {\"role\": \"system\", \"content\": ORIGINAL_RESPONSE_PROMPT}, {\"role\": \"user\", \"content\": inpt}, {\"role\": \"system\", \"content\":FEEDBACK_FORMAT_PROMPT_WITH_RESPONSE}]\n","      else: # If not, then we just pass the shorter prompt without the response\n","        refinement_history = [{\"role\": \"system\", \"content\": FEEDBACK_PROMPT_START}, {\"role\": \"user\", \"content\": rationale}, {\"role\": \"system\", \"content\":FEEDBACK_FORMAT_PROMPT_WITHOUT_RESPONSE}]\n","      openai_ss_out = client.chat.completions.create(model=MODEL, messages=refinement_history, max_tokens=MAX_TOKENS, temperature = TEMPERATURE)  # TODO: Use different model,  temperature, max token for the second stage\n","      role_ss, content_ss = extract_response(openai_ss_out)  # ss: second stage\n","      try:\n","        refined_content_json = json.loads(content_ss)  #  Parse response into JSON\n","        refined_feedback = str(refined_content_json[\"Feedback\"])\n","        refined_feedback_cell.value = refined_feedback  # Write the refined feedback into the excel sheet.\n","      except:\n","        refined_feedback_cell.value = \"---\"  # If OpenAI / parsing fails for whatever reason.\n","  except:\n","    score_cell.value = \"---\"\n","    rationale_cell.value = \"---\"  # Failsafe\n","    if TWO_STAGE:\n","      refined_feedback_cell.value = \"---\""]},{"cell_type":"markdown","metadata":{"id":"Pvd9C9skROrl"},"source":["## Save Excel Sheet"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GckhEy2oRNme"},"outputs":[],"source":["FILE_NAME = \"OutputSheet_max\"+str(MAX_TOKENS)+\"tokens_temp\"+str(TEMPERATURE)  # Change file name here.\n","if RUN_UP_TO >= 0:\n","  FILE_NAME = FILE_NAME+\"_first\"+str(RUN_UP_TO)+\"resp\"\n","if TWO_STAGE:\n","  FILE_NAME = FILE_NAME+\"_twostage\"\n","if TWO_STAGE_INCLUDE_RESPONSE:\n","  FILE_NAME = FILE_NAME+\"_include_resp_in_prompt\"\n","\n","FILE_NAME = FILE_NAME + \".xlsx\"\n","\n","workbook.save(FILE_NAME)  # Save the new file with OpenAI output into the file system"]}],"metadata":{"colab":{"provenance":[{"file_id":"10pv6Rzj4KmLo3M-66o7JQWYlRkJsZKks","timestamp":1713375895284}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
