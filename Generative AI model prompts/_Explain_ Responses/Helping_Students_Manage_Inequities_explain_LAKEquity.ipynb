{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11698,"status":"ok","timestamp":1725886025891,"user":{"displayName":"Danielle Thomas","userId":"12678519897137807718"},"user_tz":240},"id":"U3y0JUEVu_Zu","outputId":"df246ef1-0308-402f-82a0-aed6d2f0546a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting openai\n","  Downloading openai-1.44.0-py3-none-any.whl.metadata (22 kB)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n","Collecting httpx<1,>=0.23.0 (from openai)\n","  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n","Collecting jiter<1,>=0.4.0 (from openai)\n","  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n","Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.8)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n","Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n","  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n","Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n","  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n","Downloading openai-1.44.0-py3-none-any.whl (367 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m367.8/367.8 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: jiter, h11, httpcore, httpx, openai\n","Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 jiter-0.5.0 openai-1.44.0\n"]}],"source":["!pip install openai  # OpenAI API for prompting GPT-4o/GPT-4o-turbo"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":182,"status":"ok","timestamp":1725886827949,"user":{"displayName":"Danielle Thomas","userId":"12678519897137807718"},"user_tz":240},"id":"8IkheaXGsir1"},"outputs":[],"source":["import openpyxl\n","from openai import OpenAI\n","import os\n","import json\n","from tqdm import tqdm"]},{"cell_type":"markdown","metadata":{"id":"qmGkH0WztTIc"},"source":["# Reading Excel Sheet"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":391,"status":"ok","timestamp":1725887236856,"user":{"displayName":"Danielle Thomas","userId":"12678519897137807718"},"user_tz":240},"id":"vy8VfjjdtJsh"},"outputs":[],"source":["path = \"ReRun.xlsx\"\n","workbook = openpyxl.load_workbook(path)\n","sheet = workbook.active  # There is only one sheet, so no ambiguity here."]},{"cell_type":"markdown","metadata":{"id":"5uKQIYXct0_j"},"source":["Get all the responses and scores"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":165,"status":"ok","timestamp":1725887243579,"user":{"displayName":"Danielle Thomas","userId":"12678519897137807718"},"user_tz":240},"id":"SaaEXbQ_tjSs"},"outputs":[],"source":["INPUT_COLUMN = 6 # Specify the column from which input is read (A->1, B->2, etc.)\n","APPLY_FILTER = False\n","row_count = 171 # sheet.max_row  # Get number of rows. If number of rows to read is already known (or sheet does not terminate where data terminates), place number here (+1) instead.\n","INPUT_FILTER_DICTIONARY = {10: ([\"Mixed\"], True), 4: ([\n","    \"3. Why do you think the approach you selected in the previous question will best support Jeremiah by assisting him with advocating for himself? <br/>\",\n","    \"3. Why do you think the approach you selected in the previous question will best support Alexis by assisting her with advocating for herself? <br/>\",\n","    \"11. Why do you think the approach you selected in the previous question will best support Alexis by assisting her with advocating for herself? <br/>\",\n","    \"11. Why do you think the approach you selected in the previous question will best support Jeremiah by assisting him with advocating for himself? <br/>\"], True)}\n","\n","\n","# Function to check if a row matches the filter criteria\n","def matches_filters(sheet, row, filter_dict):\n","    for col, (valid_values, is_valid) in filter_dict.items():\n","        cell_value = sheet.cell(row=row, column=col).value\n","        if (cell_value in valid_values) != is_valid:\n","            return False\n","    return True\n","\n","# Read the input data\n","inputs = []\n","for i in range(2, row_count + 1):\n","    if not APPLY_FILTER or matches_filters(sheet, i, INPUT_FILTER_DICTIONARY):\n","        cell_value = sheet.cell(row=i, column=INPUT_COLUMN).value\n","        if cell_value is not None:\n","            inputs.append(cell_value)\n","\n","# Now `inputs` contains only the filtered data\n","#inputs = [sheet.cell(row=i, column=INPUT_COLUMN).value  for i in range(2, row_count + 1)]  # Column number is set here. YOUR INPUT COLUMN NUMBER GOES HERE.\n","#inputs = [x for x in inputs if x is not None]"]},{"cell_type":"markdown","metadata":{"id":"qASEYdU1vH08"},"source":["# OpenAI and Prompt Setup"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":215,"status":"ok","timestamp":1725887247660,"user":{"displayName":"Danielle Thomas","userId":"12678519897137807718"},"user_tz":240},"id":"AGO9f6uLvKiB"},"outputs":[],"source":["API_KEY = # Insert your API Key here.\n","client = OpenAI(api_key=API_KEY)"]},{"cell_type":"markdown","metadata":{"id":"HhcWKgsOP_gx"},"source":[]},{"cell_type":"markdown","metadata":{"id":"cKg2bQ7qvi_i"},"source":["Scoring Prompt Input"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":214,"status":"ok","timestamp":1725887259618,"user":{"displayName":"Danielle Thomas","userId":"12678519897137807718"},"user_tz":240},"id":"wfyoLemuvkrN"},"outputs":[],"source":["SCORING_PROMPT_START = \"\"\"\n","Please assess a tutor’s response within a tutor training scenario involving a tutor instructing a middle school student to advocate for themselves when they are experiencing an inequity. Educators and tutors should apply the strategy of assisting students in identifying when they are experiencing an inequity and instruct them to advocate for themselves. The tutor is explaining the rationale behind their response. Assess and score the tutor’s response, as follows:\n","\n","-if the tutor's response demonstrates that they recognize that the student needs support in advocating for themselves and encourages the student to act, score with a 1.\n","-if the tutor's response does not demonstrate that the tutor understands that the student needs support in advocating for themselves, score with a 0.\n","Response Start ---\n","\"\"\"\n","\n","SCORING_FORMAT_PROMPT = \"\"\"\n","--- Response End. Given the earlier response, please return a JSON string following the format, {\\\"Rationale\\\": \\\"your reasoning here\\\", \\\"Score\\\":1/0}.\n","\"\"\"\n"]},{"cell_type":"markdown","metadata":{"id":"HH0uEw5_ythd"},"source":["Feedback Elaboration Prompt"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":183,"status":"ok","timestamp":1725887261660,"user":{"displayName":"Danielle Thomas","userId":"12678519897137807718"},"user_tz":240},"id":"jJcXaVTByysS"},"outputs":[],"source":["# Second prompt: Pass feedback and the original input to the rewriter. Can omit the original input later to save on token cost.\n","\n","FEEDBACK_PROMPT_START = \"\"\"\n","Please write the following third-person feedback about a tutor into the second person. In doing so, please address the tutor directly and do not exceed 100 words.\n","Please start with positive feedback, if any. Subsequently, please provide any critiques, if applicable, in a constructive tone.\n","\n","Third-person Feedback Start ---\n","\"\"\"\n","\n","# Design choice: Passing original input to potentially provide more concrete second-person feedback (original feedback could be high-level). Can omit to reduce cost\n","ORIGINAL_RESPONSE_PROMPT = \"\"\"\n","--- Third-person Feedback End. For further context, the original feedback was provided for the following response:\n","\n","Response Start ---\n","\"\"\"\n","\n","FEEDBACK_FORMAT_PROMPT_WITH_RESPONSE = \"\"\"\n","--- Response End. Please return your refined feedback, based on the original response and the third-person feedback, in a JSON string following the format, {\\\"Feedback\\\": \\\"your response here\\\"}.\n","\"\"\"\n","\n","FEEDBACK_FORMAT_PROMPT_WITHOUT_RESPONSE = \"\"\"\n","--- Third-person Feedback End. Please return your refined feedback, based on the third-person feedback, in a JSON string following the format, {\\\"Feedback\\\": \\\"your response here\\\"}.\n","\"\"\""]},{"cell_type":"markdown","metadata":{"id":"VuVI8e8kxT87"},"source":["Helper function for response parsing"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":175,"status":"ok","timestamp":1725887263507,"user":{"displayName":"Danielle Thomas","userId":"12678519897137807718"},"user_tz":240},"id":"uIlxCT-ixV5J"},"outputs":[],"source":["def extract_response(response_obj, json=False):\n","  role = response_obj.choices[0].message.role\n","  content = response_obj.choices[0].message.content\n","  if json:\n","    return {\"role\": role, \"content\": content}\n","  else:\n","    return (role, content)"]},{"cell_type":"markdown","metadata":{"id":"jIHBTOqTwW1T"},"source":["## OpenAI API Call"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":548108,"status":"ok","timestamp":1725887821907,"user":{"displayName":"Danielle Thomas","userId":"12678519897137807718"},"user_tz":240},"id":"Ms4Iojj3wWGw","outputId":"fffbbf5f-afb1-4753-cc0a-d50da8a27d0b"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 169/169 [09:07<00:00,  3.24s/it]\n"]}],"source":["# Iterate over all responses\n","MAX_TOKENS = 300\n","TEMPERATURE = 0\n","RUN_UP_TO =  171  # Sets a maximum index for responses to run. Useful to specify how many responses we want to run on (partial execution). Set to -1 to run them all.\n","TWO_STAGE = False  # Specifies whether to refine the feedback provided by the scoring prompt\n","TWO_STAGE_INCLUDE_RESPONSE = False # Specifies whether the second-stage prompt uses the original response.\n","SCORE_COLUMN = 17  # Change column numbers here to  modify where output is written\n","RATIONALE_COLUMN= 18\n","REFINED_RATIONALE_COLUMN= 19\n","\n","\n","MODEL = \"gpt-4-turbo\"\n","\n","# Add titling to the new columns\n","output_score_title = sheet.cell(row=1, column=SCORE_COLUMN)  # Output Score Column goes here. CHANGE COLUMN NUMBER to set score output location\n","output_score_title.value = \"OpenAI Score\"  # OPTIONAL: Sets title cell in row 1. Comment out to disable this\n","\n","rationale_title = sheet.cell(row=1, column=RATIONALE_COLUMN)\n","rationale_title.value = \"OpenAI Rationale\"\n","\n","if TWO_STAGE:  # Creates a new column for the refined rationale\n","  refined_rationale_title = sheet.cell(row=1, column=REFINED_RATIONALE_COLUMN)\n","  if TWO_STAGE_INCLUDE_RESPONSE:  # If the second-stage prompt also uses the original response, use a different column title\n","    refined_rationale_title.value = \"Refined Feedback (w/ Response in prompt)\"\n","  else:\n","    refined_rationale_title.value = \"Refined Feedback (w/o response in prompt)\"\n","\n","\n","if RUN_UP_TO >=  0:  # If an upper bound is set\n","  inputs_upto = inputs[:RUN_UP_TO]\n","else:\n","  inputs_upto = inputs  # Take the whole set of responses\n","\n","for index, inpt in tqdm(enumerate(inputs_upto), total=len(inputs_upto)):\n","  overall_history = [{\"role\": \"system\", \"content\": SCORING_PROMPT_START}, {\"role\": \"user\", \"content\": inpt}, {\"role\": \"system\", \"content\": SCORING_FORMAT_PROMPT}]\n","  openai_out = client.chat.completions.create(model=MODEL, messages=overall_history, max_tokens=MAX_TOKENS, temperature = TEMPERATURE)\n","  role, content = extract_response(openai_out)\n","  # We now need to parse the JSON into rational and score\n","  score_cell = sheet.cell(row=index+2, column=SCORE_COLUMN) # Score cell\n","  rationale_cell = sheet.cell(row=index+2, column=RATIONALE_COLUMN)  # Rationale cell\n","  refined_feedback_cell = sheet.cell(row=index+2, column=REFINED_RATIONALE_COLUMN)  # Refined feedback cell\n","  try:\n","    content_json = json.loads(content)  # Run response through JSON\n","    score = str(content_json[\"Score\"])  # Cast to string to avoid type inequality\n","    rationale = str(content_json[\"Rationale\"])  # Fetch the rationale\n","\n","    score_cell.value = score  # Now write both into the Excel sheet\n","    rationale_cell.value = rationale\n","\n","    if TWO_STAGE:  # If we are to refine the feedback\n","      if TWO_STAGE_INCLUDE_RESPONSE: # If we also want to pass the response, then we need to use a longer prompt, specified next:\n","        refinement_history = [{\"role\": \"system\", \"content\": FEEDBACK_PROMPT_START}, {\"role\": \"user\", \"content\": rationale}, {\"role\": \"system\", \"content\": ORIGINAL_RESPONSE_PROMPT}, {\"role\": \"user\", \"content\": inpt}, {\"role\": \"system\", \"content\":FEEDBACK_FORMAT_PROMPT_WITH_RESPONSE}]\n","      else: # If not, then we just pass the shorter prompt without the response\n","        refinement_history = [{\"role\": \"system\", \"content\": FEEDBACK_PROMPT_START}, {\"role\": \"user\", \"content\": rationale}, {\"role\": \"system\", \"content\":FEEDBACK_FORMAT_PROMPT_WITHOUT_RESPONSE}]\n","      openai_ss_out = client.chat.completions.create(model=MODEL, messages=refinement_history, max_tokens=MAX_TOKENS, temperature = TEMPERATURE)  # TODO: Use different model,  temperature, max token for the second stage\n","      role_ss, content_ss = extract_response(openai_ss_out)  # ss: second stage\n","      try:\n","        refined_content_json = json.loads(content_ss)  #  Parse response into JSON\n","        refined_feedback = str(refined_content_json[\"Feedback\"])\n","        refined_feedback_cell.value = refined_feedback  # Write the refined feedback into the excel sheet.\n","      except:\n","        refined_feedback_cell.value = \"---\"  # If OpenAI / parsing fails for whatever reason.\n","  except:\n","    score_cell.value = \"---\"\n","    rationale_cell.value = \"---\"  # Failsafe\n","    if TWO_STAGE:\n","      refined_feedback_cell.value = \"---\""]},{"cell_type":"markdown","metadata":{"id":"Pvd9C9skROrl"},"source":["## Save Excel Sheet"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":204,"status":"ok","timestamp":1725887849067,"user":{"displayName":"Danielle Thomas","userId":"12678519897137807718"},"user_tz":240},"id":"GckhEy2oRNme"},"outputs":[],"source":["FILE_NAME = \"OutputSheet_max\"+str(MAX_TOKENS)+\"tokens_temp\"+str(TEMPERATURE)  # Change file name here.\n","if RUN_UP_TO >= 0:\n","  FILE_NAME = FILE_NAME+\"_first\"+str(RUN_UP_TO)+\"resp\"\n","if TWO_STAGE:\n","  FILE_NAME = FILE_NAME+\"_twostage\"\n","if TWO_STAGE_INCLUDE_RESPONSE:\n","  FILE_NAME = FILE_NAME+\"_include_resp_in_prompt\"\n","\n","FILE_NAME = FILE_NAME + \".xlsx\"\n","\n","workbook.save(FILE_NAME)  # Save the new file with OpenAI output into the file system"]}],"metadata":{"colab":{"provenance":[{"file_id":"1XdWm69dwW1BK1RcO9ejYvBOQRh6P1ke5","timestamp":1713970537536},{"file_id":"10pv6Rzj4KmLo3M-66o7JQWYlRkJsZKks","timestamp":1713375895284}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
